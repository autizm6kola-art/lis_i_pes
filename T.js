const fs = require("fs");
const path = require("path");

const inputPath = path.join(__dirname, "input.txt"); // —Ç–≤–æ–π –∏—Å—Ö–æ–¥–Ω—ã–π txt
const outputPath = path.join(__dirname, "output.json");

const START_NUMBER = 1; // üëà –Ω–∞—á–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä

// —á–∏—Ç–∞–µ–º —Ñ–∞–π–ª
const text = fs.readFileSync(inputPath, "utf-8");

// —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞–∑–±–∏–≤–∫–∏ —Å—Ç—Ä–æ–∫–∏ –Ω–∞ —Å–ª–æ–≤–∞ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
function tokenize(line) {
  const tokens = [];

  const regex = /[–ê-–Ø–∞-—è–Å—ëA-Za-z0-9]+(?:-[–ê-–Ø–∞-—è–Å—ëA-Za-z0-9]+)*|[.,!?;:‚Äì‚Äî-]/g;

  const matches = line.match(regex) || [];

  for (const match of matches) {
    const isWord = /[–ê-–Ø–∞-—è–Å—ëA-Za-z0-9]/.test(match);
    tokens.push({
      word: match,
      type: isWord ? "word" : "punctuation"
    });
  }

  return tokens;
}

// –æ—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ä—Å–∏–Ω–≥
const result = text
  .split(/\r?\n/)
  .map(line => line.trim())
  .filter(Boolean)
  .map((line, index) => {
    return {
      id: START_NUMBER + index,
      content: tokenize(line)
    };
  });

// –∑–∞–ø–∏—Å—ã–≤–∞–µ–º JSON
fs.writeFileSync(outputPath, JSON.stringify(result, null, 2), "utf-8");

console.log(`‚úÖ –ì–æ—Ç–æ–≤–æ! JSON —Å–æ–∑–¥–∞–Ω. –ù—É–º–µ—Ä–∞—Ü–∏—è —Å ${START_NUMBER}`);
